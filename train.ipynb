{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scikit-learn classifiers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Scikit-learn model evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Scikit-learn ensemble methods\n",
    "from sklearn.ensemble import StackingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and evaluate multiple classifiers using TF-IDF transformed text data. \n",
    "def model_building(df):\n",
    "\n",
    "    X = df['transformed_text']\n",
    "    y = df['spam']\n",
    "\n",
    "    # TF-IDF Vectorization\n",
    "    tfidf = TfidfVectorizer(max_features=3000)\n",
    "    X_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=2)\n",
    "\n",
    "    # Initialize classifiers\n",
    "    clfs = {\n",
    "        'SVC': SVC(kernel='sigmoid', gamma=1.0),\n",
    "        'KN': KNeighborsClassifier(),\n",
    "        'NB': MultinomialNB(),\n",
    "        'DT': DecisionTreeClassifier(max_depth=5),\n",
    "        'LR': LogisticRegression(solver='liblinear', penalty='l1'),\n",
    "        'RF': RandomForestClassifier(n_estimators=50, random_state=2),\n",
    "        'AdaBoost': AdaBoostClassifier(n_estimators=50, random_state=2),\n",
    "        'BgC': BaggingClassifier(n_estimators=50, random_state=2),\n",
    "        'ETC': ExtraTreesClassifier(n_estimators=50, random_state=2),\n",
    "        'GBDT': GradientBoostingClassifier(n_estimators=50, random_state=2),\n",
    "        'xgb': XGBClassifier(n_estimators=50, random_state=2)\n",
    "    }\n",
    "\n",
    "    # Function to train a classifier and return accuracy and precision scores\n",
    "    def train_classifier(clf, X_train, y_train, X_test, y_test):\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        return accuracy, precision\n",
    "\n",
    "    accuracy_scores = []\n",
    "    precision_scores = []\n",
    "\n",
    "    # Train and evaluate each classifier\n",
    "    for name, clf in clfs.items():\n",
    "        current_accuracy, current_precision = train_classifier(clf, X_train, y_train, X_test, y_test)\n",
    "        print(\"For \", name)\n",
    "        print(\"Accuracy - \", current_accuracy)\n",
    "        print(\"Precision - \", current_precision)\n",
    "        accuracy_scores.append(current_accuracy)\n",
    "        precision_scores.append(current_precision)\n",
    "\n",
    "    # Store the performance metrics\n",
    "    performance_df = pd.DataFrame({'Algorithm': clfs.keys(), 'Accuracy': accuracy_scores, 'Precision': precision_scores}).sort_values('Precision', ascending=False)\n",
    "\n",
    "    return performance_df, clfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_models(df, models):\n",
    "    X = df['transformed_text']\n",
    "    y = df['spam']\n",
    "\n",
    "    # TF-IDF Vectorization\n",
    "    tfidf = TfidfVectorizer(max_features=3000)\n",
    "    X_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "    # Split data into train and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_tfidf, y, test_size=0.2, random_state=2)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for name, clf in models.items():\n",
    "        print(f\"Validating {name}...\")\n",
    "\n",
    "        # Fit on train data\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # Score on train and validation sets\n",
    "        train_score = clf.score(X_train, y_train)\n",
    "        val_score = clf.score(X_val, y_val)\n",
    "\n",
    "        # Predictions on train and validation sets\n",
    "        y_train_pred = clf.predict(X_train)\n",
    "        y_val_pred = clf.predict(X_val)\n",
    "\n",
    "        # Evaluate on train and validation sets\n",
    "        train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "        train_precision = precision_score(y_train, y_train_pred)\n",
    "        val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "        val_precision = precision_score(y_val, y_val_pred)\n",
    "        val_report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "        # Fine-tune using train and validation sets if necessary\n",
    "        if hasattr(clf, 'best_params_'):\n",
    "            print(f\"Fine-tuning {name}...\")\n",
    "            clf = clf.best_estimator_\n",
    "\n",
    "        results.append({\n",
    "            'Algorithm': name,\n",
    "            'Train Score': train_score,\n",
    "            'Validation Score': val_score,\n",
    "            'Train Accuracy': train_accuracy,\n",
    "            'Train Precision': train_precision,\n",
    "            'Validation Accuracy': val_accuracy,\n",
    "            'Validation Precision': val_precision,\n",
    "            'Validation Report': val_report\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_validate_models(df):\n",
    "    # Build models\n",
    "    performance_df, clfs = model_building(df)\n",
    "\n",
    "    # Fine-tuning parameters for classifiers that support it\n",
    "    param_grids = {\n",
    "        'SVC': {'kernel': ['sigmoid', 'rbf'], 'gamma': [1.0, 0.1, 0.01]},\n",
    "        'DT': {'max_depth': [3, 5, 7]},\n",
    "        'RF': {'n_estimators': [50, 100, 200]},\n",
    "        'AdaBoost': {'n_estimators': [50, 100, 200], 'learning_rate': [0.1, 0.5, 1.0]},\n",
    "        'GBDT': {'n_estimators': [50, 100, 200], 'learning_rate': [0.1, 0.5, 1.0]},\n",
    "        'xgb': {'n_estimators': [50, 100, 200], 'learning_rate': [0.1, 0.5, 1.0]}\n",
    "    }\n",
    "\n",
    "    clfs_copy = clfs.copy()\n",
    "\n",
    "    # Update classifiers with GridSearchCV for fine-tuning\n",
    "    for name in param_grids:\n",
    "        if name in clfs_copy:\n",
    "            clfs_copy[name] = GridSearchCV(clfs_copy[name], param_grids[name], cv=3)\n",
    "\n",
    "    # Validate models\n",
    "    validation_results = validate_models(df, clfs_copy)\n",
    "\n",
    "    return performance_df, validation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model(df, benchmark_models):\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    def train_test_split_df(test_size):\n",
    "        X = df['transformed_text']\n",
    "        y = df['spam']\n",
    "\n",
    "        tfidf = TfidfVectorizer()\n",
    "        X_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=test_size)\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    # Train the benchmark models\n",
    "    def train_benchmark_models(benchmark_models, X_train, y_train):\n",
    "        for name, model in benchmark_models.items():\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "        return benchmark_models\n",
    "\n",
    "    # Evaluate the benchmark models.\n",
    "    def evaluate_benchmark_models(benchmark_models, X_test, y_test):\n",
    "        evaluation_scores = {}\n",
    "\n",
    "        for name, model in benchmark_models.items():\n",
    "            y_pred = model.predict(X_test)\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            evaluation_scores[name] = {'Accuracy': accuracy, 'Precision': precision}\n",
    "\n",
    "        return evaluation_scores\n",
    "\n",
    "    # Select the best model based on evaluation scores\n",
    "    def select_best_model(evaluation_scores):\n",
    "        best_model = max(evaluation_scores, key=lambda k: (evaluation_scores[k]['Accuracy'], evaluation_scores[k]['Precision']))\n",
    "\n",
    "        return best_model\n",
    "    \n",
    "    # Apply stacking ensemble learning  \n",
    "    def apply_stacking(models, X_train, y_train, X_test, y_test):\n",
    "        final_estimator = RandomForestClassifier()\n",
    "\n",
    "        clf = StackingClassifier(estimators=list(models.items()), final_estimator=final_estimator)\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        evaluation_scores = {'Accuracy': accuracy, 'Precision': precision}\n",
    "\n",
    "        return evaluation_scores\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split_df(0.2)\n",
    "    \n",
    "    benchmark_models = train_benchmark_models(benchmark_models, X_train, y_train)\n",
    "    evaluation_scores = evaluate_benchmark_models(benchmark_models, X_test, y_test)\n",
    "    best_model = select_best_model(evaluation_scores)\n",
    "    evaluation_scores_ensemble = apply_stacking(models, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    return benchmark_models, evaluation_scores, best_model, evaluation_scores_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
